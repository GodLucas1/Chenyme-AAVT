import os
import json
import toml
import time
from pathlib import Path
import datetime
import streamlit as st
import streamlit_antd_components as sac

from config.config import load_config, ModelMappins
from styles.global_style import style
from utils.public import (FileToMp3, OpenaiWhisperResult, runWhisperSeperateProc, translate, local_translate,
                          generate_srt_from_result, generate_srt_from_result_2, srt_mv, parse_srt_file, convert_to_srt,
                          show_video, add_font_settings, srt_to_ass, srt_to_vtt, srt_to_sbv)

style()

import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

path = os.getcwd() + "/"
llms_path = "config/llms.toml"
whisper_path = "config/whisper.toml"
font_data_path = "config/font.txt"
audio_config_path = "config/audio.toml"
prompt_config_path = "config/prompt.json"
project_config_path = "config/project.toml"
audio_cache_path = path + "cache/audio/"

with open(font_data_path, 'r', encoding='utf-8') as file:
    lines = file.readlines()
    fonts = [line.strip() for line in lines]

LOCAL_CONFIG = load_config()
prompt = LOCAL_CONFIG.prompt
home_key = LOCAL_CONFIG.llms["Home"]["key"]  # home
home_url = LOCAL_CONFIG.llms["Home"]["url"]
home_model = LOCAL_CONFIG.llms["Home"]["model"]

local_key = LOCAL_CONFIG.llms["Local"]["key"]  # Local
local_url = LOCAL_CONFIG.llms["Local"]["url"]
local_model = LOCAL_CONFIG.llms["Local"]["model"]

custom_key = LOCAL_CONFIG.llms["Custom"]["key"]  # Custom
custom_base = LOCAL_CONFIG.llms["Custom"]["url"]
custom_model = LOCAL_CONFIG.llms["Custom"]["model"]

global_key = LOCAL_CONFIG.llms["Global"]["key"]  # Global
global_url = LOCAL_CONFIG.llms["Global"]["url"]

chatgpt_key = LOCAL_CONFIG.llms["ChatGPT"]["key"]  # Openai
chatgpt_url = LOCAL_CONFIG.llms["ChatGPT"]["url"]

claude_key = LOCAL_CONFIG.llms["Claude"]["key"]  # claude
claude_url = LOCAL_CONFIG.llms["Claude"]["url"]

gemini_key = LOCAL_CONFIG.llms["Gemini"]["key"]  # Gemini
gemini_url = LOCAL_CONFIG.llms["Gemini"]["url"]

deepseek_key = LOCAL_CONFIG.llms["DeepSeek"]["key"]  # deepseek
deepseek_url = LOCAL_CONFIG.llms["DeepSeek"]["url"]

kimi_key = LOCAL_CONFIG.llms["Kimi"]["key"]  # kimi
kimi_base = LOCAL_CONFIG.llms["Kimi"]["url"]

chatglm_key = LOCAL_CONFIG.llms["ChatGLM"]["key"]  # chatglm
chatglm_url = LOCAL_CONFIG.llms["ChatGLM"]["url"]

ai01_key = LOCAL_CONFIG.llms["Yi"]["key"]  # 01
ai01_url = LOCAL_CONFIG.llms["Yi"]["url"]

whisper_mode = LOCAL_CONFIG.whisper["Mode"]["WhisperMode"]  # whisper_mode

whisper_temp = LOCAL_CONFIG.whisper["OpenAI"]["Temp"]  # whisper_temp
whisper_prompt = LOCAL_CONFIG.whisper["OpenAI"]["Prompt"]  # whisper_mode

faster_gpu = LOCAL_CONFIG.whisper["Faster"]["GPU"]  # faster_gpu
faster_vad = LOCAL_CONFIG.whisper["Faster"]["VAD"]  # faster_vad
faster_temp = LOCAL_CONFIG.whisper["Faster"]["Temp"]  # faster_temp
faster_prompt = LOCAL_CONFIG.whisper["Faster"]["Prompt"]  # faster_prompt
faster_min_vad = LOCAL_CONFIG.whisper["Faster"]["min_vad"]  # faster_min_vad
faster_beam_size = LOCAL_CONFIG.whisper["Faster"]["beam_size"]  # faster_beam_size

faster_local_path = LOCAL_CONFIG.whisper["Faster_Local"]["path"]  # æ¨¡å‹è·¯å¾„
faster_local_gpu = LOCAL_CONFIG.whisper["Faster_Local"]["GPU"]  # GPU åŠ é€Ÿ
faster_local_vad = LOCAL_CONFIG.whisper["Faster_Local"]["VAD"]  # VAD
faster_local_temp = LOCAL_CONFIG.whisper["Faster_Local"]["Temp"]  # æ¸©åº¦
faster_local_prompt = LOCAL_CONFIG.whisper["Faster_Local"]["Prompt"]  # æç¤ºè¯
faster_local_min_vad = LOCAL_CONFIG.whisper["Faster_Local"]["min_vad"]  # æœ€å° VAD æŒç»­æ—¶é—´
faster_local_beam_size = LOCAL_CONFIG.whisper["Faster_Local"]["beam_size"]  # Beam Size

language = LOCAL_CONFIG.audio["whisper"]["language_list"]
openai_whisper_model_list = LOCAL_CONFIG.audio["whisper"]["openai_whisper_model_list"]
faster_whisper_model_list = LOCAL_CONFIG.audio["whisper"]["faster_whisper_model_list"]
language_index = LOCAL_CONFIG.audio["whisper"]["language_index"]
openai_whisper_model_index = LOCAL_CONFIG.audio["whisper"]["openai_whisper_model_index"]
faster_whisper_model_index = LOCAL_CONFIG.audio["whisper"]["faster_whisper_model_index"]
faster_whisper_model_local_index = LOCAL_CONFIG.audio["whisper"]["faster_whisper_model_local_index"]

translate_index = LOCAL_CONFIG.audio["translate"]["translate_index"]
language2 = LOCAL_CONFIG.audio["translate"]["language_list"]
language2_index1 = LOCAL_CONFIG.audio["translate"]["language_index1"]
language2_index2 = LOCAL_CONFIG.audio["translate"]["language_index2"]
wait_time_setting = LOCAL_CONFIG.audio["translate"]["wait_time"]
prompt_pre_setting = LOCAL_CONFIG.audio["translate"]["prompt"]
system_prompt = LOCAL_CONFIG.prompt[prompt_pre_setting]["system_prompt"].replace("{language1}",
                                                                                 language2_index1).replace(
    "{language2}", language2_index2)
user_prompt = LOCAL_CONFIG.prompt[prompt_pre_setting]["user_prompt"].replace("{language1}", language2_index1).replace(
    "{language2}", language2_index2)

srt_setting = LOCAL_CONFIG.audio["subtitle"]["srt"]
audio_readme = LOCAL_CONFIG.audio["other"]["first"]

translation_dict = ModelMappins.translation_dict


@st.dialog("ä½¿ç”¨æç¤º")
def AudioReadme():
    st.write("""
    ## æ¬¢è¿é¦–æ¬¡ä½¿ç”¨ AIå…¨è‡ªåŠ¨éŸ³é¢‘ç¿»è¯‘ åŠŸèƒ½ï¼

    ä¸ºäº†ç¡®ä¿é¡ºåˆ©è¿è¡Œå¹¶è·å¾—æœ€ä½³ä½“éªŒï¼Œè¯·å…³é—­æ­¤å¼¹çª—åï¼Œå‰å¾€é¡µé¢ä¸­çš„**å‚æ•°è®¾ç½®**æ¨¡å—ï¼Œè¿›è¡Œå¿…è¦çš„å‚æ•°é…ç½®ã€‚
    
    è¯·åŠ¡å¿…æ ¹æ®æ‚¨çš„éœ€æ±‚åŠæ—¶è°ƒæ•´è®¾ç½®ï¼Œä»¥æé«˜ç¿»è¯‘çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

    æ›´å¤šå‚è€ƒèµ„æºï¼š
    - ğŸ“˜ [ç›¸å…³æ•™ç¨‹](https://blog.chenyme.top/blog/aavt-install)
    - ğŸ“‚ [é¡¹ç›®åœ°å€](https://github.com/Chenyme/Chenyme-AAVT)
    - ğŸ’¬ [äº¤æµç¾¤ç»„](https://t.me/+j8SNSwhS7xk1NTc9)
    
    """)
    st.write("")

    if st.button("**æˆ‘å·²çŸ¥æ™“&nbsp;&nbsp;&nbsp;ä¸å†å¼¹å‡º**", type="primary", use_container_width=True,
                 key="blog_first_button"):
        with open(audio_config_path, 'w', encoding="utf-8") as f:
            LOCAL_CONFIG.audio["other"]["first"] = True
            toml.dump(LOCAL_CONFIG.audio, f)
        st.session_state.read = True
        st.rerun()
    st.write("")


if not audio_readme:
    AudioReadme()
if "save" in st.session_state:
    st.toast("å‚æ•°å·²æˆåŠŸä¿å­˜", icon=":material/verified:")
    del st.session_state["save"]
if "read" in st.session_state:
    st.toast("æ¬¢è¿ä½¿ç”¨ ~", icon=":material/verified:")
    del st.session_state["read"]
if "upload" in st.session_state:
    st.toast("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼", icon=":material/verified:")
    del st.session_state["upload"]

tab1, tab2 = st.tabs(["**éŸ³é¢‘è¯†åˆ«**", "**å‚æ•°è®¾ç½®**"])
with tab2:
    @st.dialog("è¯­è¨€è¯´æ˜")
    def Audio_lang():
        st.write(
            "**å¼ºåˆ¶æŒ‡å®šè§†é¢‘è¯­è¨€ä¼šæé«˜è¯†åˆ«å‡†ç¡®åº¦ï¼Œä½†ä¹Ÿå¯èƒ½ä¼šé€ æˆè¯†åˆ«å‡ºé”™ã€‚** \n\n`è‡ªåŠ¨è¯†åˆ«` - è‡ªåŠ¨æ£€æµ‹è¯­è¨€ (Auto Detect) \n\n`zh` - ä¸­æ–‡ (Chinese) - ä¸­æ–‡ \n\n`en` - è‹±è¯­ (English) - English \n\n`ja` - æ—¥è¯­ (Japanese) - æ—¥æœ¬èª \n\n`th` - æ³°è¯­ (Thai) - à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ \n\n`de` - å¾·è¯­ (German) - Deutsch \n\n`fr` - æ³•è¯­ (French) - franÃ§ais \n\n`ru` - ä¿„è¯­ (Russian) - Ğ ÑƒÑÑĞºĞ¸Ğ¹ \n\n`ko` - éŸ©è¯­ (Korean) - í•œêµ­ì–´ \n\n`vi` - è¶Šå—è¯­ (Vietnamese) - Tiáº¿ng Viá»‡t \n\n`it` - æ„å¤§åˆ©è¯­ (Italian) - Italiano \n\n`ar` - é˜¿æ‹‰ä¼¯è¯­ (Arabic) - Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© \n\n`es` - è¥¿ç­ç‰™è¯­ (Spanish) - EspaÃ±ol \n\n`bn` - å­ŸåŠ æ‹‰è¯­ (Bengali) - à¦¬à¦¾à¦‚à¦²à¦¾ \n\n`pt` - è‘¡è„ç‰™è¯­ (Portuguese) - PortuguÃªs \n\n`hi` - å°åœ°è¯­ (Hindi) - à¤¹à¤¿à¤‚à¤¦à¥€")


    AudioSave = st.container()
    AudioSetting = st.container(border=True)

    with AudioSetting:
        st.write("#### Whisper è¯†åˆ«å‚æ•° ")
        st.write("")
        if whisper_mode == "OpenAIWhisper - API":
            st.write("###### è¯†åˆ«æ¨¡å‹")
            st.caption("ä½¿ç”¨ OpenAI API æ”¯æŒè°ƒç”¨çš„ Whisper æ¨¡å‹ ")
            openai_whisper_model_index = st.selectbox("Whisper æ¨¡å‹", openai_whisper_model_list,
                                                      openai_whisper_model_list.index(openai_whisper_model_index),
                                                      label_visibility="collapsed")
            st.write("")
        if whisper_mode == "FasterWhisper - AutoDownload":
            st.write("###### è¯†åˆ«æ¨¡å‹")
            st.caption("ä½¿ç”¨ FasterWhisper æ”¯æŒè°ƒç”¨çš„ Whisper æ¨¡å‹ ")
            faster_whisper_model_index = st.selectbox("Whisper æ¨¡å‹", faster_whisper_model_list,
                                                      faster_whisper_model_list.index(faster_whisper_model_index),
                                                      label_visibility="collapsed")
        if whisper_mode == "FasterWhisper - LocalModel":
            st.write("###### è¯†åˆ«æ¨¡å‹")
            st.caption(
                "ä½¿ç”¨å·²éƒ¨ç½²åˆ°æœ¬åœ°çš„ FasterWhisper æ¨¡å‹ | [æ”¯æŒçš„æ¨¡å‹](https://huggingface.co/Systran) | [ä½¿ç”¨æ•™ç¨‹](https://blog.chenyme.top/blog/aavt-install#bfd48658b23b)")
            model_names = os.listdir(faster_local_path)
            try:
                faster_whisper_model_local_index = st.selectbox("Whisper æœ¬åœ°æ¨¡å‹", model_names,
                                                                model_names.index(faster_whisper_model_local_index),
                                                                label_visibility="collapsed")
            except:
                faster_whisper_model_local_index = st.selectbox("Whisper æœ¬åœ°æ¨¡å‹", model_names)
        st.write("")
        if whisper_mode != "OpenAIWhisper - API":
            st.write("###### è§†é¢‘è¯­è¨€")
            st.caption("å¼ºåˆ¶æŒ‡å®šè§†é¢‘è¯­è¨€")
            col1, col2 = st.columns([0.95, 0.05])
            with col1:
                language_index = st.selectbox('Media è¯­è¨€', language, index=language.index(language_index),
                                              label_visibility="collapsed")
            with col2:
                if st.button("**?**", use_container_width=True):
                    Audio_lang()

        st.write("")
        st.write("#### LLMs ç¿»è¯‘å‚æ•° ")
        st.write("")
        st.write("###### ç¿»è¯‘å¼•æ“")
        st.caption("ç¿»è¯‘æ¨¡å—ä½¿ç”¨çš„å¼•æ“ï¼Œè¯·ç¡®ä¿æ‚¨å·²åœ¨å…¨å±€è®¾ç½®ä¸­é…ç½®å¯¹åº”çš„å¼•æ“å‚æ•°ï¼")
        items_list = [sac.CasItem('æ— éœ€ç¿»è¯‘'),
                      sac.CasItem('Local / æœ¬åœ°æ¨¡å‹', icon='house-up-fill')]
        model_dict = ModelMappins.model_dict
        for privider, models_list in model_dict.items():
            items_list.append(sac.CasItem(privider, icon='folder2', children=[
                sac.CasItem(model, icon='folder2-open') for model in models_list
            ]))

        translate_index = sac.cascader(items=items_list, label='', search=True, index=translate_index, return_index=True)
        if translate_index != [0]:
            st.write("")
            col1, col2 = st.columns(2)
            with col1:
                st.write("###### åŸå§‹è¯­è¨€")
                st.caption("æ–‡ä»¶çš„åŸå§‹è¯­è¨€")
                language2_index1 = st.selectbox('åŸå§‹è¯­è¨€', language2, index=language2.index(language2_index1),
                                                label_visibility="collapsed")
            with col2:
                st.write("###### ç›®æ ‡è¯­è¨€")
                st.caption("æ–‡ä»¶çš„ç›®æ ‡è¯­è¨€")
                language2_index2 = st.selectbox('ç›®æ ‡è¯­è¨€', language2, index=language2.index(language2_index2),
                                                label_visibility="collapsed")
            st.write("")
            st.write("###### ç¿»è¯‘æç¤ºè¯")
            st.caption("ç¿»è¯‘ä½¿ç”¨çš„æç¤ºè¯ï¼Œå¯å‰å¾€å…¨å±€è®¾ç½®-ç¿»è¯‘è®¾ç½®ä¸­é…ç½®æ–°çš„æç¤ºè¯")
            try:
                prompt_pre_setting = st.selectbox('é¢„è®¾ prompt', prompt.keys(),
                                                  index=list(prompt.keys()).index(prompt_pre_setting),
                                                  label_visibility="collapsed")
            except:
                prompt_pre_setting = st.selectbox('é¢„è®¾ prompt', prompt.keys(), label_visibility="collapsed")
            st.write("")
            st.write("###### API è°ƒç”¨é—´éš” / s")
            st.caption(
                "ç¿»è¯‘æ—¶APIçš„è°ƒç”¨é—´éš”ã€‚è¯·å‚é˜…æ‚¨çš„APIæœåŠ¡å•†æ–‡æ¡£ä¸­çš„ æ¯åˆ†é’Ÿè°ƒç”¨æœ€å¤§é™åˆ¶é€Ÿç‡ è¿›è¡Œé€‚å½“è°ƒæ•´ï¼Œè‹¥ç¿»è¯‘æ—¶é‡åˆ°æŠ¥é”™ 429ï¼š`Too Many Requests`ã€`RateLimitError` è¯·é€‚å½“å¢å¤§é—´éš”ã€‚")
            wait_time_setting = st.number_input('ç¿»è¯‘é—´éš”(s)', min_value=0.0, max_value=5.0, value=wait_time_setting,
                                                step=0.1, label_visibility="collapsed")

        st.write("")
        st.write("#### Subtitle å­—å¹•å‚æ•° ")
        st.write("")
        st.write("###### åŒè¯­å­—å¹•")
        st.caption("é€‰æ‹©åŒè¯­å­—å¹•çš„æ˜¾ç¤ºæ ·å¼")
        srt_choose = ["å…³é—­", "åŸå§‹è¯­è¨€ä¸ºé¦–", "ç›®æ ‡è¯­è¨€ä¸ºé¦–"]
        srt_setting = st.selectbox('åŒè¯­å­—å¹•', srt_choose, index=srt_choose.index(srt_setting),
                                   label_visibility="collapsed")
        st.write("")

    with AudioSave:
        col1, col2 = st.columns([0.75, 0.25])
        st.write("")
        with col2:
            st.write("")
            st.write("")
            if st.button("**ä¿å­˜æ›´æ”¹**", use_container_width=True, type="primary"):
                with open(audio_config_path, 'w', encoding="utf-8") as f:
                    LOCAL_CONFIG.audio["whisper"]["language_index"] = language_index
                    LOCAL_CONFIG.audio["whisper"]["openai_whisper_model_index"] = openai_whisper_model_index
                    LOCAL_CONFIG.audio["whisper"]["faster_whisper_model_index"] = faster_whisper_model_index
                    LOCAL_CONFIG.audio["whisper"]["faster_whisper_model_local_index"] = faster_whisper_model_local_index

                    LOCAL_CONFIG.audio["translate"]["translate_index"] = translate_index
                    LOCAL_CONFIG.audio["translate"]["language_index1"] = language2_index1
                    LOCAL_CONFIG.audio["translate"]["language_index2"] = language2_index2
                    LOCAL_CONFIG.audio["translate"]["wait_time"] = wait_time_setting
                    LOCAL_CONFIG.audio["translate"]["prompt"] = prompt_pre_setting

                    LOCAL_CONFIG.audio["subtitle"]["srt"] = srt_setting

                    toml.dump(LOCAL_CONFIG.audio, f)
                    st.session_state.save = True
                    st.rerun()
        with col1:
            st.write("")
            st.write("")
            st.write("### æ›´æ”¹å‚æ•°è®¾ç½®")
            st.caption("Changing Parameter Settings")

with tab1:
    # é…ç½®å¤„ç†
    faster_whisper_model_local_index = faster_local_path + "/" + faster_whisper_model_local_index

    col1, col2 = st.columns([0.75, 0.25])  # ç½®é¡¶æ ‡é¢˜ã€æ‰§è¡ŒæŒ‰é’®æµç¨‹æ¨¡å—

    # æ ‡é¢˜æ¨¡å—
    with col1:
        st.write("")
        st.write("")
        st.subheader("AI å…¨è‡ªåŠ¨éŸ³é¢‘ç¿»è¯‘")
        st.caption("AI Automatic Audio Translation")

    # æ‰§è¡ŒæŒ‰é’®æµç¨‹æ¨¡å—
    with col2:
        st.write("")
        st.write("")
        if st.button("**å¼€å§‹è¯†åˆ«**", type="primary", use_container_width=True):
            if "uploaded_file_audio" in st.session_state:
                uploaded_file_audio = st.session_state.uploaded_file_audio
                print("\n" + "=" * 50)
                print("\n\033[1;39m*** Chenyme-AAVT AIéŸ³é¢‘è¯†åˆ« ***\033[0m")
                st.toast('ä»»åŠ¡å¼€å§‹æ‰§è¡Œï¼è¯·å‹¿åœ¨è¿è¡Œæ—¶åˆ‡æ¢èœå•æˆ–ä¿®æ”¹å‚æ•°!', icon=":material/rocket_launch:")

                msg_ved = st.toast('æ­£åœ¨å¯¹éŸ³é¢‘è¿›è¡Œé¢„å¤„ç†', icon=":material/graphic_eq:")
                current_time = datetime.datetime.now().strftime("_%Y%m%d%H%M%S")
                st.session_state.audio_name_original = uploaded_file_audio.name.split('.')[0]
                st.session_state.audio_name = "output." + uploaded_file_audio.name.split('.')[-1]
                output_file = audio_cache_path + st.session_state.audio_name_original + current_time
                os.makedirs(output_file)
                current_time = datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S")
                with open(output_file + '/' + st.session_state.audio_name, "wb") as file:
                    file.write(uploaded_file_audio.getbuffer())
                msg_ved.toast("éŸ³é¢‘é¢„å¤„ç†å®Œæˆ", icon=":material/graphic_eq:")

                print("\n\033[1;34mğŸš€ ä»»åŠ¡å¼€å§‹æ‰§è¡Œ\033[0m")
                print(f"\033[1;34mğŸ“‚ æœ¬æ¬¡ä»»åŠ¡ç›®å½•:\033[0m\033[1;34m {output_file} \033[0m")
                print("\033[1;33mâš ï¸ è¯·ä¸è¦åœ¨ä»»åŠ¡è¿è¡ŒæœŸé—´åˆ‡æ¢èœå•æˆ–ä¿®æ”¹å‚æ•°ï¼\033[0m")

                msg_whs = st.toast("æ­£åœ¨è¯†åˆ«éŸ³é¢‘å†…å®¹", icon=":material/troubleshoot:")
                if whisper_mode == "OpenAIWhisper - API":
                    result = OpenaiWhisperResult(chatgpt_key, chatgpt_url,
                                                 f"{output_file}/{st.session_state.audio_name}",
                                                 openai_whisper_model_index, whisper_prompt, whisper_temp)
                if whisper_mode == "FasterWhisper - AutoDownload":
                    result = runWhisperSeperateProc(f"{output_file}/{st.session_state.audio_name}", faster_gpu,
                                                    faster_whisper_model_index, faster_prompt, faster_temp, faster_vad,
                                                    language_index, faster_beam_size, faster_min_vad)
                if whisper_mode == "FasterWhisper - LocalModel":
                    result = runWhisperSeperateProc(f"{output_file}/{st.session_state.audio_name}", faster_local_gpu,
                                                    faster_whisper_model_local_index, faster_local_prompt,
                                                    faster_local_temp, faster_local_vad, language_index,
                                                    faster_local_beam_size, faster_local_min_vad)
                if 'error' in result:
                    print(f"\033[1;31mâŒ Whisperè¯†åˆ«å¼‚å¸¸: {result['error']}\033[0m")
                    st.error(f"å¤„ç†å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{result['error']}")
                    st.stop()
                print("\033[1;34mğŸ‰ Whisper è¯†åˆ«æˆåŠŸï¼\033[0m")
                msg_whs.toast("éŸ³é¢‘å†…å®¹è¯†åˆ«å®Œæˆ", icon=":material/colorize:")
                print("\033[1;34mğŸ‰ éŸ³é¢‘å†…å®¹è¯†åˆ«å®Œæˆï¼\033[0m")
                translate_option = translation_dict[tuple(translate_index)]
                if translate_option != 'æ— éœ€ç¿»è¯‘':
                    msg_tra = st.toast("æ­£åœ¨ç¿»è¯‘å­—å¹•", icon=":material/translate:")
                    if 'æœ¬åœ°æ¨¡å‹' in translate_option:
                        result = local_translate(system_prompt, user_prompt, local_key, local_url, local_model, result,
                                                 srt_setting)
                    elif 'gemini' in translate_option:
                        result = translate(system_prompt, user_prompt, gemini_key, gemini_url, translate_option, result,
                                           wait_time_setting, srt_setting)
                    elif 'yi' in translate_option:
                        result = translate(system_prompt, user_prompt, ai01_key, ai01_url, translate_option, result,
                                           wait_time_setting, srt_setting)
                    elif 'gpt' in translate_option:
                        result = translate(system_prompt, user_prompt, chatgpt_key, chatgpt_url, translate_option,
                                           result, wait_time_setting, srt_setting)
                    elif 'moonshot' in translate_option:
                        result = translate(system_prompt, user_prompt, kimi_key, kimi_base, translate_option, result,
                                           wait_time_setting, srt_setting)
                    elif 'glm' in translate_option:
                        result = translate(system_prompt, user_prompt, chatglm_key, chatglm_url, translate_option,
                                           result, wait_time_setting, srt_setting)
                    elif 'deepseek' in translate_option:
                        result = translate(system_prompt, user_prompt, deepseek_key, deepseek_url, translate_option,
                                           result, wait_time_setting, srt_setting)
                    elif 'claude' in translate_option:
                        result = translate(system_prompt, user_prompt, claude_key, claude_url, translate_option, result,
                                           wait_time_setting, srt_setting)
                    print("\033[1;34mğŸ‰ å­—å¹•ç¿»è¯‘å·²å®Œæˆï¼\033[0m")
                    msg_tra.toast("ç¿»è¯‘ä»»åŠ¡ç»“æŸï¼", icon=":material/translate:")

                msg_srt = st.toast('æ­£åœ¨ç”ŸæˆSRTå­—å¹•æ–‡ä»¶', icon=":material/edit_note:")
                print("\n\033[1;35m*** æ­£åœ¨ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶ ***\033[0m\n")
                srt_content = generate_srt_from_result(result)
                with open(output_file + "/output.srt", 'w', encoding='utf-8') as srt_file:
                    srt_file.write(srt_content)
                st.session_state.output_file_audio = output_file

                print("\033[1;34mğŸ‰ ä»»åŠ¡æˆåŠŸç»“æŸï¼\033[0m")
                print("\n" + "=" * 50 + "\n")
            else:
                st.toast("è¯·å…ˆåœ¨å·¥å…·æ ä¸­ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼", icon=":material/release_alert:")

    st.write("")
    with st.expander("**Audio Preview / éŸ³è½¨é¢„è§ˆ**", expanded=True, icon=":material/graphic_eq:"):
        col6, col7 = st.columns([0.9999999, 0.0000001])

    st.write("")
    col1, col2 = st.columns([0.75, 0.25])
    with col2:
        with st.expander("**Tool / å·¥å…·**", expanded=True, icon=":material/construction:"):
            st.caption("ä¸Šä¼ æ–‡ä»¶")


            @st.dialog("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
            def upload_audio():
                st.write("åœ¨è¿™é‡Œä¸Šä¼ æ‚¨éœ€è¦å¤„ç†çš„è§†é¢‘æ–‡ä»¶ã€‚")
                st.write(
                    "è¯·æ³¨æ„ï¼Œé™¤å…³é—­ CMD å¤–ï¼Œæ‰§è¡Œä»»åŠ¡åæ— æ³•å–æ¶ˆä»»åŠ¡ï¼è¯·å‹¿åœ¨æ‰§è¡Œæ—¶ç‚¹å‡»ä»»ä½• é¡¹ç›®æŒ‰é’® æˆ– åˆ‡æ¢èœå•ï¼Œä»¥å…å¯¼è‡´è¯†åˆ«æŠ¥é”™ï¼")
                st.write("")
                uploaded_file_audio = st.file_uploader("ä¸Šä¼ æ‚¨çš„éŸ³é¢‘æ–‡ä»¶", type=["mp3", "mpga", "m4a", "wav"],
                                                       label_visibility="collapsed")
                st.write("")
                if st.button("**ç‚¹å‡»ä¸Šä¼ **", use_container_width=True, type="primary"):
                    st.session_state.uploaded_file_audio = uploaded_file_audio
                    st.session_state.upload = True
                    st.rerun()
                st.write("")


            if st.button('**æ–‡ä»¶ä¸Šä¼ **', use_container_width=True, type="primary", key="upload_audio_button"):
                upload_audio()

            st.caption("å­—å¹•å·¥å…·")
            if st.button('**ä¿å­˜ä¿®æ”¹**', use_container_width=True, type="primary", key="audio_change"):
                try:
                    with open(st.session_state.output_file_audio + "/output.srt", 'w', encoding='utf-8') as srt_file:
                        srt_file.write(st.session_state.srt_content_new_audio)
                    st.toast("å·²æˆåŠŸä¿å­˜", icon=":material/task_alt:")
                except:
                    st.toast("æœªæ£€æµ‹åˆ°è¿è¡Œåçš„å­—å¹•æ–‡ä»¶", icon=":material/error:")

            if st.button('**æ‰“å¼€ç›®å½•**', use_container_width=True, type="primary", key="audio_open"):
                try:
                    os.startfile(st.session_state.output_file_audio)
                    st.toast("æ³¨æ„ï¼šæ–‡ä»¶å¤¹å·²æˆåŠŸæ‰“å¼€ï¼Œå¯èƒ½æœªç½®é¡¶æ˜¾ç¤ºï¼Œè¯·æ£€æŸ¥ä»»åŠ¡æ ï¼", icon=":material/task_alt:")
                except:
                    st.toast("æœªè¿›è¡Œè¯†åˆ«ï¼Œç›®å½•å°šæœªç”Ÿæˆï¼", icon=":material/error:")
            st.divider()

            if st.toggle("**æ›´å¤šåŠŸèƒ½**"):
                st.caption("å­—å¹•è½´é«˜åº¦")
                height = st.number_input("é«˜åº¦æ˜¾ç¤º", min_value=300, step=100, value=550, label_visibility="collapsed")
                st.session_state.height_audio = height
                st.caption("å…¶ä»–å­—å¹•æ ¼å¼")
                try:
                    captions_option = st.radio('æ›´å¤šå­—å¹•æ ¼å¼å¯¼å‡º', ('VTT', 'ASS', 'SBV'), index=0,
                                               label_visibility="collapsed")
                    if captions_option == 'VTT':
                        vtt_content = srt_to_vtt(st.session_state.srt_content_new_audio)
                        st.download_button(
                            label="**VTT ä¸‹è½½**",
                            data=vtt_content.encode('utf-8'),
                            key='vtt_download',
                            file_name='output.vtt',
                            mime='text/vtt',
                            use_container_width=True,
                            type="primary"
                        )
                    elif captions_option == 'ASS':
                        sbv_content = srt_to_ass(st.session_state.srt_content_new_audio, "Arial", "18", "#FFFFFF")
                        st.download_button(
                            label="**ASS ä¸‹è½½**",
                            data=sbv_content.encode('utf-8'),
                            key='ass_download',
                            file_name='output.ass',
                            mime='text/ass',
                            use_container_width=True,
                            type="primary"
                        )
                    elif captions_option == 'SBV':
                        sbv_content = srt_to_sbv(st.session_state.srt_content_new_audio)
                        st.download_button(
                            label="**SBV ä¸‹è½½**",
                            data=sbv_content.encode('utf-8'),
                            key='sbv_download',
                            file_name='output.sbv',
                            mime='text/sbv',
                            use_container_width=True,
                            type="primary"
                        )
                except:
                    if st.button('**ä¸‹è½½å­—å¹•**', use_container_width=True, type="primary"):
                        st.toast("æœªæ£€æµ‹åˆ°å­—å¹•ç”Ÿæˆï¼", icon=":material/error:")

            if "height_audio" not in st.session_state:
                st.session_state.height_audio = 550

    with col1:
        with st.expander("**Subtitle Preview / å­—å¹•é¢„è§ˆ**", expanded=True, icon=":material/subtitles:"):
            try:
                st.caption("å­—å¹•æ—¶é—´è½´")
                with open(st.session_state.output_file_audio + "/output.srt", 'r', encoding='utf-8') as srt_file:
                    srt_content = srt_file.read()
                srt_data1 = parse_srt_file(srt_content, srt_setting)
                edited_data = st.data_editor(srt_data1, height=st.session_state.height_audio, hide_index=True,
                                             use_container_width=True)
                srt_data2 = convert_to_srt(edited_data, srt_setting)
                st.session_state.srt_content_new_audio = srt_data2
            except:
                st.info(
                    "##### ç»“æœé¢„è§ˆåŒºåŸŸ \n\n&nbsp;\n\n**ç”Ÿæˆå®Œæ¯•åä¼šåœ¨æ­¤åŒºåŸŸè‡ªåŠ¨æ˜¾ç¤ºå­—å¹•æ—¶é—´è½´**\n\n è¿è¡Œå‰ï¼Œè¯·åœ¨å³ä¾§ä½¿ç”¨ä¸Šä¼ æ–‡ä»¶å·¥å…·å¯¼å…¥ä½ çš„éŸ³é¢‘æ–‡ä»¶ï¼ \n\n&nbsp;\n\n&nbsp;",
                    icon=":material/view_in_ar:")
                st.write("")

    with col6:
        try:
            st.caption("éŸ³é¢‘éŸ³è½¨")
            audio_file = open(f"{st.session_state.output_file_audio}/{st.session_state.audio_name}", "rb")
            audio_bytes = audio_file.read()
            st.audio(audio_bytes)
        except:
            try:
                audio_bytes = st.session_state.uploaded_file_audio.getvalue()
                st.audio(audio_bytes)
            except:
                st.info(
                    "##### éŸ³è½¨é¢„è§ˆåŒºåŸŸ \n\n&nbsp;**è¿è¡Œåè‡ªåŠ¨æ˜¾ç¤º | æŸ¥çœ‹ [é¡¹ç›®æ–‡æ¡£](https://blog.chenyme.top/blog/aavt-install) | åŠ å…¥ [äº¤æµç¾¤ç»„](https://t.me/+j8SNSwhS7xk1NTc9)**",
                    icon=":material/view_in_ar:")
                st.write("")
